{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\lenovo\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\lenovo\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\lenovo\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_path = 'Dataset.csv'\n",
    "output_path = 'PreprocessedDataset.csv'\n",
    "\n",
    "import pandas as pd\n",
    "import re\n",
    "import nltk \n",
    "from nltk.tokenize import word_tokenize  \n",
    "from nltk.corpus import stopwords  \n",
    "from nltk.stem import WordNetLemmatizer  \n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words('english'))\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "custom_stopwords = set([\"rt\", \"amp\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    text = re.sub(r'http\\S+', '', text)\n",
    "    text = re.sub(r'[^A-Za-z\\s]', '', text)\n",
    "    return text.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_tweet(text):\n",
    "    text = clean_text(text)\n",
    "    tokens = word_tokenize(text)\n",
    "    tokens = [word for word in tokens if word not in stop_words and word not in custom_stopwords]\n",
    "    tokens = [lemmatizer.lemmatize(token) for token in tokens]\n",
    "    return ' '.join(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Party                                              Tweet  \\\n",
      "0  Republican  RT @RepRyanCostello: I supported @CongressmanD...   \n",
      "1  Republican  RT @HASCRepublicans: LIVE: Chairman @RepMikeTu...   \n",
      "2    Democrat  During #SmallBusinessWeek, I shared some the w...   \n",
      "3    Democrat  Yet another court has struck down @realDonaldT...   \n",
      "4  Republican  RT @AARPOhio: More focus on Ohio's 1.5 million...   \n",
      "\n",
      "                                  preprocessed_tweet  \n",
      "0  repryancostello supported congressmandan repsi...  \n",
      "1  hascrepublicans live chairman repmiketurner le...  \n",
      "2  smallbusinessweek shared way san diego office ...  \n",
      "3  yet another court struck realdonaldtrumps hear...  \n",
      "4  aarpohio focus ohio million family caregiver t...  \n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(file_path)\n",
    "\n",
    "df = df[df['Tweet'].apply(lambda x: isinstance(x, str))]\n",
    "\n",
    "df['preprocessed_tweet'] = df['Tweet'].apply(preprocess_tweet)\n",
    "\n",
    "df.to_csv(output_path, index=False)\n",
    "\n",
    "print(df[['Party', 'Tweet', 'preprocessed_tweet']].head())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
